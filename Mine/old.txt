
# --- dimensionality reduction --- #
# LLE = partial(manifold.LocallyLinearEmbedding,
#               eigen_solver='dense',
#               neighbors_algorithm='auto',
#               random_state=42)
# methods = OrderedDict()
# methods['RAW'] = None
# nb_components_pca = list(range(0, data_train_test.shape[1], 5))
# for i in nb_components_pca:
#      pca = PCA(n_components=i)
#      X_train_pca = pca.fit_transform(X_train)
#      print('Total Explained Variance Ratio using {} components = {}%'.format(i, round(np.sum(pca.explained_variance_ratio_)*100, 2)))
# methods['PCA'] = PCA(n_components=35)
# nb_neighbors = 25
# nb_components = 20
# methods['LLE'] = LLE(n_neighbors=nb_neighbors, n_components=nb_components, method="standard")
# methods['MLLE'] = LLE(n_neighbors=nb_neighbors, n_components=nb_components, method="modified")
# elapsed_dr = OrderedDict()
# X_train_dict = OrderedDict()
# X_test_dict = OrderedDict()
# labels_dr = ['RAW', 'PCA', 'LLE', 'MLLE']
# for label in labels_dr:
#     if label == 'RAW':
#         X_train_dict[label] = X_train
#         X_test_dict[label] = X_test
#         elapsed_dr['RAW'] = 0
#         continue
#     start_time = time.time()
#     X_train_dict[label] = methods[label].fit_transform(X_train)
#     X_test_dict[label] = methods[label].transform(X_test)
#     elapsed_time = time.time() - start_time
#     elapsed_dr[label] = elapsed_time
#     print(label + ' finished in ' + f'{elapsed_time:.2f}' + ' s!')
# # set-up lle vs mlle figure
# list_comb = list(range(nb_components))
# list_comb = list(combinations(list_comb, 2))
# nb_pairs = min(len(list_comb), 5)
# list_comb = list_comb[:nb_pairs]
# fig, axs = plt.subplots(nb_pairs, 2, squeeze=False, figsize=(35, 18))
# fig.suptitle('Manifold Learning with %i neighbors and %i embeddings' % (nb_neighbors, nb_components), fontsize=14)
# for m, label in enumerate(labels_dr):
#     if label == 'PCA' or label == 'RAW':
#         continue
#     train = X_train_dict[label]
#     n = m - 2
#     for (l, x) in enumerate(list_comb):
#         axs[l, n].scatter(train[y_train == 0, x[0]],
#                           train[y_train == 0, x[1]], c='green', label='Survived')
#         axs[l, n].scatter(train[y_train == 1, x[0]],
#                           train[y_train == 1, x[1]], c='red', label='Died')
#         if l == 0:
#             axs[l, n].set_title('%s (%.2g sec)' % (label, elapsed_dr[label]))
#         axs[l, n].xaxis.set_major_formatter(NullFormatter())
#         axs[l, n].yaxis.set_major_formatter(NullFormatter())
#         axs[l, n].axis('tight')
#         axs[l, n].legend()
#         axs[l, n].set_xlabel(f'dim : {x[0]}')
#         axs[l, n].set_ylabel(f'dim : {x[1]}')
# fig.savefig('LLE_MLLE.png')

nb_neighbors = np.arange(3, 6, 2)
# print(nb_neighbors)
mesh = np.zeros((nb_neighbors[-1], 1))
# print(len(nb_neighbors), nb_neighbors[-1])
for nb_neighbor in nb_neighbors:
    comp = np.arange(1, nb_neighbor-1, 1)
    comp = np.append(comp, np.zeros(nb_neighbors[-1] - len(comp)))
    comp = np.reshape(comp, (len(comp), 1))
    mesh = np.hstack((mesh, comp))
mesh = mesh[:, 1:]
mesh = mesh.astype(int)
# print(mesh)
neighbors_algorithm = ['ball_tree', 'kd_tree', 'brute']
methods = OrderedDict()
elapsed_dr = OrderedDict()
X_train_dict = OrderedDict()
X_test_dict = OrderedDict()
labels_dr = []
for i in range(len(nb_neighbors)):
    temp = mesh[:, i]
    for j in range(temp.shape[0]):
        if temp[j] == 0:
            break
        for k in neighbors_algorithm:
            labels_dr.append('LLE:' + str(nb_neighbors[i]) + ':' + str(temp[j]) + ':' + k)
            labels_dr.append('MLLE:' + str(nb_neighbors[i]) + ':' + str(temp[j]) + ':' + k)
LLE = partial(manifold.LocallyLinearEmbedding,
              eigen_solver='dense',
              random_state=42)
for label in labels_dr:
    if label.split(':')[0] == 'LLE':
        methods[label] = LLE(n_neighbors=int(label.split(':')[1]), n_components=int(label.split(':')[2]), method="standard", neighbors_algorithm=label.split(':')[3])
    elif label.split(':')[0] == 'MLLE':
        methods[label] = LLE(n_neighbors=int(label.split(':')[1]), n_components=int(label.split(':')[2]), method="modified", neighbors_algorithm=label.split(':')[3])
    start_time = time.time()
    X_train_dict[label] = methods[label].fit_transform(X_train)
    X_test_dict[label] = methods[label].transform(X_test)
    elapsed_time = time.time() - start_time
    elapsed_dr[label] = elapsed_time
    print(label + ' finished in ' + f'{elapsed_time:.2f}' + ' s!')

# --- set-up classification --- #
# classifiers = OrderedDict()
# classifiers['Linear_SVM'] = LinearSVC(penalty='l2', loss='squared_hinge', dual=False, C=1,
#                                       fit_intercept=False, intercept_scaling=1,
#                                       class_weight='balanced', max_iter=1000, random_state=42)
# classifiers['RBF_SVM'] = SVC(C=1, kernel='rbf', gamma=0.5, probability=False, class_weight='balanced')
# classifiers['KNN'] = KNeighborsClassifier(n_neighbors=5, weights='uniform', algorithm='auto', metric='minkowski',
#                                           p=2, metric_params=None)
# classifiers['GMM'] = GaussianMixture(n_components=2, covariance_type='full', init_params='kmeans')
# labels_clf = ['Linear_SVM', 'RBF_SVM', 'KNN', 'GMM']
# elapsed_tot = []
# precision_scores = []
# recall_scores = []
# f1_scores = []
# accuracy_scores = []
# cms = []
# rocs = []
# states = []
# # # main loop
# for label_clf in labels_clf:
#     for label_dr in labels_dr:
#         start_time = time.time()
#         classifiers[label_clf].fit(X_train_dict[label_dr], y_train)
#         predictions = classifiers[label_clf].predict(X_test_dict[label_dr])
#         elapsed_time = time.time() - start_time
#         elapsed_tot.append(elapsed_time+elapsed_dr[label_dr])
#         states.append(label_clf + ':' + label_dr + ':' + f'{elapsed_tot[-1]:.2f}')
#         # precision_scores.append(metrics.precision_score(y_test, predictions, average='weighted'))
#         # recall_scores.append(metrics.recall_score(y_test, predictions, average='weighted'))
#         f1_scores.append(metrics.f1_score(y_test, predictions, average='weighted'))
#         accuracy_scores.append(metrics.accuracy_score(y_test, predictions))
#         cms.append(metrics.confusion_matrix(y_test, predictions, normalize='true'))
#         rocs.append(metrics.roc_curve(y_test, predictions))
#         print(label_clf + ' on ' + label_dr + ' finished in ' + f'{elapsed_time:.2f}' + ' s!')
# result = {'states': states, 'f1_scores': f1_scores, 'accuracy_scores': accuracy_scores,
#           'time': elapsed_tot, 'cms': cms, 'rocs': rocs}
# result_df = pd.DataFrame(data=result)
# result_df.to_csv('./results.csv')
# # # set-up figures
# result_df_reduced = result_df[['f1_scores', 'accuracy_scores']]
# ax = result_df_reduced.plot(kind='bar', figsize=(40, 40))
# ax.set_xticklabels(states, rotation=45, fontsize=20)
# plt.savefig('results.png')
# fig, axs = plt.subplots(len(labels_clf), len(labels_dr), squeeze=False, figsize=(40, 20))
# counter = 0
# for i in range(len(labels_clf)):
#     for j in range(len(labels_dr)):
#         sns.heatmap(cms[counter], annot=True, ax=axs[i, j])
#         axs[i, j].set_title(states[counter], fontsize=20)
#         counter = counter + 1
# fig.savefig('confusion_matrix.png')
# fig, axs = plt.subplots(len(labels_clf), len(labels_dr), squeeze=False, figsize=(40, 20))
# counter = 0
# for i in range(len(labels_clf)):
#     for j in range(len(labels_dr)):
#         fpr, tpr, _ = rocs[counter]
#         axs[i, j].plot(fpr, tpr)
#         axs[i, j].set_title(states[counter], fontsize=20)
#         counter = counter + 1
# fig.savefig('roc_curves.png')

classifiers = OrderedDict()
classifiers['RBF_SVM'] = SVC(C=1.0, kernel='rbf', gamma='scale', probability=False, class_weight='balanced')
labels_clf = ['RBF_SVM']
elapsed_tot = []
f1_scores = []
accuracy_scores = []
states = []
# # main loop
for label_clf in labels_clf:
    for label_dr in labels_dr:
        start_time = time.time()
        classifiers[label_clf].fit(X_train_dict[label_dr], y_train)
        predictions = classifiers[label_clf].predict(X_test_dict[label_dr])
        elapsed_time = time.time() - start_time
        elapsed_tot.append(elapsed_time+elapsed_dr[label_dr])
        states.append(label_clf + ':' + label_dr + ':' + f'{elapsed_tot[-1]:.2f}')
        f1_scores.append(metrics.f1_score(y_test, predictions, average='weighted'))
        accuracy_scores.append(metrics.accuracy_score(y_test, predictions))
        print(label_clf + ' on ' + label_dr + ' finished in ' + f'{elapsed_time:.2f}' + ' s!')
result_dr = {'states': states, 'f1_scores': f1_scores, 'accuracy_scores': accuracy_scores, 'time': elapsed_tot}
result_dr_df = pd.DataFrame(data=result_dr)
result_dr_df.to_csv('./result_dr.csv')
# # set-up figures
ax = result_dr_df.plot(y=['f1_scores', 'accuracy_scores'], style='x-', figsize=(60, 20), xticks=states)
plt.savefig('./result_dr.png')

# result_df_reduced = result_df[['f1_scores', 'accuracy_scores']]
# ax = result_df_reduced.plot(kind='bar', figsize=(40, 40))
# ax.set_xticklabels(states, rotation=45, fontsize=20)
# plt.savefig('results.png')
# fig, axs = plt.subplots(len(labels_clf), len(labels_dr), squeeze=False, figsize=(40, 20))
# counter = 0
# for i in range(len(labels_clf)):
#     for j in range(len(labels_dr)):
#         sns.heatmap(cms[counter], annot=True, ax=axs[i, j])
#         axs[i, j].set_title(states[counter], fontsize=20)
#         counter = counter + 1
# fig.savefig('confusion_matrix.png')
# fig, axs = plt.subplots(len(labels_clf), len(labels_dr), squeeze=False, figsize=(40, 20))
# counter = 0
# for i in range(len(labels_clf)):
#     for j in range(len(labels_dr)):
#         fpr, tpr, _ = rocs[counter]
#         axs[i, j].plot(fpr, tpr)
#         axs[i, j].set_title(states[counter], fontsize=20)
#         counter = counter + 1
# fig.savefig('roc_curves.png')
# --- dummy --- #
# # 01
# print(X.info(verbose=True, show_counts=True))
# print(Y.info(verbose=True, show_counts=True))
# print(sampled_data.info(verbose=True, show_counts=True))
# print(death_proportion)
# # 02
# pca = PCA()
# X_train_pca = pca.fit_transform(X_train)
# X_test_pca = pca.transform(X_test)
# explained_variance_s = pca.explained_variance_ratio_
# plt.figure(figsize=(10, 8))
# plt.plot(explained_variance_s)
# plt.show()
# nb_components = [2, 3, 4, 5, 6, 7, 8, 9, 10, 20, 30, 40, 50, 60, 70, 80, 90, 97]
# for i in nb_components:
#      pca = PCA(n_components=i)
#      X_train_pca = pca.fit_transform(X_train)
#      print('Total Explained Variance Ratio using {} components = {}%'.format(i, round(np.sum(pca.explained_variance_ratio_)*100, 2)))
# # 03
# result_df.insert(loc=0, column='Classifier', value=labels)

